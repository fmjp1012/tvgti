{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import inv, eigvals, norm\n",
    "import matplotlib.pyplot as plt\n",
    "import cvxpy as cp\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "from multiprocessing import Manager\n",
    "\n",
    "from utils import *\n",
    "from models.tvgti_pc_nonsparse import TimeVaryingSEM as TimeVaryingSEM_PC_NONSPARSE\n",
    "from models.tvgti_pp_nonsparse_undirected_nonoverlap import TimeVaryingSEM as TimeVaryingSEM_PP_NONSPARSE_UNDIRECTED_NONOVERLAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_S(N, sparsity, max_weight):\n",
    "    S = np.zeros((N, N))\n",
    "    \n",
    "    for i in range(N):\n",
    "        for j in range(i + 1, N):\n",
    "            if np.random.rand() < sparsity:\n",
    "                weight = np.random.uniform(-max_weight, max_weight)\n",
    "                # weight = np.random.uniform(0, max_weight)\n",
    "                S[i, j] = weight\n",
    "                S[j, i] = weight\n",
    "    \n",
    "    # Ensure spectral radius < 1\n",
    "    spectral_radius = max(abs(eigvals(S)))\n",
    "    if spectral_radius >= 1:\n",
    "        S = S / (spectral_radius + 0.1)\n",
    "\n",
    "    S = S / norm(S)\n",
    "    return S\n",
    "\n",
    "def generate_random_S_with_off_diagonal(N, sparsity, max_weight):\n",
    "    S = np.zeros((N, N))\n",
    "    \n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if i != j and np.random.rand() < sparsity:\n",
    "                weight = np.random.uniform(-max_weight, max_weight)\n",
    "                # weight = np.random.uniform(0, max_weight)\n",
    "                S[i, j] = weight\n",
    "    \n",
    "    # Ensure spectral radius < 1\n",
    "    spectral_radius = max(abs(eigvals(S)))\n",
    "    if spectral_radius >= 1:\n",
    "        S = S / (spectral_radius + 0.1)\n",
    "\n",
    "    S = S / norm(S)\n",
    "    return S\n",
    "\n",
    "def modify_S(S, edge_indices, factor=2.0):\n",
    "    S_modified = S.copy()\n",
    "    for (i, j) in edge_indices:\n",
    "        if i != j:\n",
    "            S_modified[i, j] *= factor\n",
    "            S_modified[j, i] *= factor\n",
    "    return S_modified\n",
    "\n",
    "def generate_stationary_X(N, T, S_is_symmetric, sparsity, max_weight, std_e):\n",
    "    if S_is_symmetric:\n",
    "        S = generate_random_S(N, sparsity=sparsity, max_weight=max_weight)\n",
    "    else:\n",
    "        S = generate_random_S_with_off_diagonal(N, sparsity=sparsity, max_weight=max_weight)\n",
    "    S_series = [S for _ in range(T)]\n",
    "    e_t_series = np.random.normal(0, std_e, size=(N, T))\n",
    "\n",
    "    I = np.eye(N)\n",
    "    try:\n",
    "        inv_I_S = inv(I - S)\n",
    "    except np.linalg.LinAlgError:\n",
    "        raise ValueError(\"The matrix (I - S) is non-invertible. Please adjust S to ensure invertibility.\")\n",
    "\n",
    "    X = inv_I_S @ e_t_series\n",
    "\n",
    "    return S_series, X, e_t_series\n",
    "\n",
    "def generate_stationary_X_from_S(S, N, T, std_e):\n",
    "    S = S\n",
    "    S_series = [S for _ in range(T)]\n",
    "    e_t_series = np.random.normal(0, std_e, size=(N, T))\n",
    "\n",
    "    I = np.eye(N)\n",
    "    try:\n",
    "        inv_I_S = inv(I - S)\n",
    "    except np.linalg.LinAlgError:\n",
    "        raise ValueError(\"The matrix (I - S) is non-invertible. Please adjust S to ensure invertibility.\")\n",
    "\n",
    "    X = inv_I_S @ e_t_series\n",
    "\n",
    "    return S_series, X\n",
    "\n",
    "def generate_piecewise_X(N, T, S_is_symmetric, sparsity, max_weight, std_e):\n",
    "    max_weight_0 = max_weight\n",
    "    max_weight_1 = max_weight\n",
    "    if S_is_symmetric:\n",
    "        S0 = generate_random_S(N, sparsity=sparsity, max_weight=max_weight)\n",
    "    else:\n",
    "        S0 = generate_random_S_with_off_diagonal(N, sparsity=sparsity, max_weight=max_weight)\n",
    "    # S1 = generate_random_S(N, sparsity=sparsity, max_weight=max_weight_1)\n",
    "    S1 = S0*2\n",
    "    S_series = [S0 for _ in range(T // 2)] + [S1 for _ in range(T - T // 2)]\n",
    "    e_t_series = np.random.normal(0, std_e, size=(N, T))\n",
    "\n",
    "    I = np.eye(N)\n",
    "    try:\n",
    "        inv_I_S0 = inv(I - S0)\n",
    "        inv_I_S1 = inv(I - S1)\n",
    "    except np.linalg.LinAlgError:\n",
    "        raise ValueError(\"The matrix (I - S) is non-invertible. Please adjust S to ensure invertibility.\")\n",
    "\n",
    "    X0 = inv_I_S0 @ e_t_series[:, :T // 2]\n",
    "    X1 = inv_I_S1 @ e_t_series[:, T // 2:]\n",
    "    X = np.concatenate([X0, X1], axis=1)\n",
    "\n",
    "    return S_series, X\n",
    "\n",
    "def generate_piecewise_X_K(N, T, S_is_symmetric, sparsity, max_weight, std_e, K):\n",
    "    S_list = []\n",
    "    inv_I_S_list = []\n",
    "    I = np.eye(N)\n",
    "\n",
    "    for i in range(K):\n",
    "        if S_is_symmetric:\n",
    "            S = generate_random_S(N, sparsity=sparsity, max_weight=max_weight)\n",
    "        else:\n",
    "            S = generate_random_S_with_off_diagonal(N, sparsity=sparsity, max_weight=max_weight)\n",
    "        S_list.append(S)\n",
    "        try:\n",
    "            inv_I_S = inv(I - S)\n",
    "            inv_I_S_list.append(inv_I_S)\n",
    "        except np.linalg.LinAlgError:\n",
    "            raise ValueError(\"The matrix (I - S) is non-invertible. Please adjust S to ensure invertibility.\")\n",
    "\n",
    "    # Divide T into K segments\n",
    "    segment_lengths = [T // K] * K\n",
    "    segment_lengths[i-1] += T % K\n",
    "\n",
    "    # Create S_series\n",
    "    S_series = []\n",
    "    for i, length in enumerate(segment_lengths):\n",
    "        S_series.extend([S_list[i]] * length)\n",
    "\n",
    "    # Generate error terms\n",
    "    e_t_series = np.random.normal(0, std_e, size=(N, T))\n",
    "\n",
    "    # Compute X\n",
    "    X_list = []\n",
    "    start = 0\n",
    "    for i, length in enumerate(segment_lengths):\n",
    "        end = start + length\n",
    "        X_i = inv_I_S_list[i] @ e_t_series[:, start:end]\n",
    "        X_list.append(X_i)\n",
    "        start = end\n",
    "\n",
    "    X = np.concatenate(X_list, axis=1)\n",
    "\n",
    "    return S_series, X\n",
    "\n",
    "\n",
    "def solve_offline_sem(X_up_to_t, lambda_reg):\n",
    "    N, t = X_up_to_t.shape\n",
    "    S = cp.Variable((N, N), symmetric=True)\n",
    "    \n",
    "    # objective = (1/(2*t)) * cp.norm(X_up_to_t - S @ X_up_to_t, 'fro') + lambda_reg * cp.norm1(S)\n",
    "    objective = (1/(2*t)) * cp.norm(X_up_to_t - S @ X_up_to_t, 'fro')\n",
    "    \n",
    "    constraints = [cp.diag(S) == 0]\n",
    "    \n",
    "    prob = cp.Problem(cp.Minimize(objective), constraints)\n",
    "    \n",
    "    prob.solve(solver=cp.SCS, verbose=False)\n",
    "    \n",
    "    if prob.status not in [\"optimal\", \"optimal_inaccurate\"]:\n",
    "        raise ValueError(\"CVXPY did not find an optimal solution.\")\n",
    "    \n",
    "    S_opt = S.value\n",
    "    return S_opt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 69\u001b[0m\n\u001b[1;32m     66\u001b[0m trial_seeds \u001b[38;5;241m=\u001b[39m [seed \u001b[38;5;241m+\u001b[39m i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_trials)]\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# 並列処理の実行\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_trials\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_trial\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial_seed\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrial_seed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrial_seeds\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# 結果の集計\u001b[39;00m\n\u001b[1;32m     74\u001b[0m error_pc_total \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(T)\n",
      "File \u001b[0;32m~/Desktop/lab/simu/tvgti/venv/lib/python3.12/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/lab/simu/tvgti/venv/lib/python3.12/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/lab/simu/tvgti/venv/lib/python3.12/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 試行回数の設定\n",
    "num_trials = 10\n",
    "\n",
    "# パラメータの設定\n",
    "N = 10\n",
    "T = 1000\n",
    "sparsity = 100\n",
    "max_weight = 0.5\n",
    "variance_e = 0.005\n",
    "std_e = np.sqrt(variance_e)\n",
    "K = 1\n",
    "S_is_symmetric = True\n",
    "\n",
    "seed = 42  # 基本のシード\n",
    "\n",
    "# TV-SEMパラメータ\n",
    "P = 0\n",
    "C = 1\n",
    "gamma = 0.999\n",
    "alpha = 0.0\n",
    "beta_pc = 1e-2 * 3\n",
    "beta_sgd = 1e-2 * 3\n",
    "\n",
    "# その他のパラメータ\n",
    "r = 4  # window size\n",
    "q = 20  # number of processors\n",
    "rho = 0.3\n",
    "\n",
    "# 試行ごとの処理を行う関数を定義\n",
    "def run_trial(trial_seed):\n",
    "    np.random.seed(trial_seed)  # シードを試行ごとに設定\n",
    "\n",
    "    # データの生成\n",
    "    S_series, X = generate_piecewise_X_K(N, T, S_is_symmetric, sparsity, max_weight, std_e, K)\n",
    "\n",
    "    # 初期値の設定\n",
    "    if S_is_symmetric:\n",
    "        S_0 = generate_random_S(N, sparsity, max_weight)\n",
    "    else:\n",
    "        S_0 = generate_random_S_with_off_diagonal(N, sparsity, max_weight)\n",
    "    S_0 = S_0 / norm(S_0)\n",
    "\n",
    "    # モデルのインスタンス化（並列処理を無効化）\n",
    "    tv_sem_pc = TimeVaryingSEM_PC_NONSPARSE(N, S_0, alpha, beta_pc, gamma, P, C)\n",
    "    tv_sem_sgd = TimeVaryingSEM_PC_NONSPARSE(N, S_0, alpha, beta_sgd, 0, P, C)\n",
    "    tv_sem_pp = TimeVaryingSEM_PP_NONSPARSE_UNDIRECTED_NONOVERLAP(N, S_0, r, q, rho)\n",
    "\n",
    "    # 並列処理を無効化するために、直接関数を呼び出す\n",
    "    estimates_pc, cost_values_pc = tv_sem_pc.run(X)\n",
    "    estimates_sgd, cost_values_sgd = tv_sem_sgd.run(X)\n",
    "    estimates_pp = tv_sem_pp.run(X)\n",
    "\n",
    "    # エラーの計算\n",
    "    error_pc = []\n",
    "    error_sgd = []\n",
    "    error_pp = []\n",
    "\n",
    "    for i in range(T):\n",
    "        error_pc.append(norm(estimates_pc[i] - S_series[i]) ** 2 / (norm(S_0 - S_series[i]) ** 2))\n",
    "        error_sgd.append(norm(estimates_sgd[i] - S_series[i]) ** 2 / (norm(S_0 - S_series[i]) ** 2))\n",
    "        error_pp.append(norm(estimates_pp[i] - S_series[i]) ** 2 / (norm(S_0 - S_series[i]) ** 2))\n",
    "\n",
    "    return error_pc, error_sgd, error_pp\n",
    "\n",
    "# 試行ごとのシードを作成\n",
    "trial_seeds = [seed + i for i in range(num_trials)]\n",
    "\n",
    "# 並列処理の実行\n",
    "results = Parallel(n_jobs=num_trials)(\n",
    "    delayed(run_trial)(trial_seed) for trial_seed in trial_seeds\n",
    ")\n",
    "\n",
    "# 結果の集計\n",
    "error_pc_total = np.zeros(T)\n",
    "error_sgd_total = np.zeros(T)\n",
    "error_pp_total = np.zeros(T)\n",
    "\n",
    "for error_pc, error_sgd, error_pp in results:\n",
    "    error_pc_total += np.array(error_pc)\n",
    "    error_sgd_total += np.array(error_sgd)\n",
    "    error_pp_total += np.array(error_pp)\n",
    "\n",
    "# 平均の計算\n",
    "error_pc_mean = error_pc_total / num_trials\n",
    "error_sgd_mean = error_sgd_total / num_trials\n",
    "error_pp_mean = error_pp_total / num_trials\n",
    "\n",
    "# 結果のプロット\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(error_pc_mean, color='blue', label='Correction Only')\n",
    "plt.plot(error_sgd_mean, color='cyan', label='SGD')\n",
    "plt.plot(error_pp_mean, color='red', label='Proposed')\n",
    "plt.yscale('log')\n",
    "plt.xlim(left=0, right=T)\n",
    "plt.xlabel('t')\n",
    "plt.ylabel('Average NSE')\n",
    "plt.legend()\n",
    "filename = (\n",
    "    f'result_N{N}_'\n",
    "    f'T{T}_'\n",
    "    f'maxweight{max_weight}_'\n",
    "    f'variancee{variance_e}_'\n",
    "    f'K{K}_'\n",
    "    f'Sissymmetric{S_is_symmetric}_'\n",
    "    f'seed{seed}_'\n",
    "    f'P{P}_'\n",
    "    f'C{C}_'\n",
    "    f'gammma{gamma}_'\n",
    "    f'betapc{beta_pc}_'\n",
    "    f'betasgd{beta_sgd}_'\n",
    "    f'r{r}_'\n",
    "    f'q{q}_'\n",
    "    f'rho{rho}_'\n",
    "    f'numtrials{num_trials}_.png'\n",
    ")\n",
    "print(filename)\n",
    "plt.savefig('./result/241125_mean/images/' + filename)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
